{
  "hash": "e0acfd3ef00a71bc0e4f038831365cec",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MINICURSO CONNEPI 2024: Regressão Linear para pesquisa tecnológica com apoio do R\"\nauthor: \n  - name: \"Alessandro de Castro Corrêa\"\n    email: alessandro.correa@ifpa.edu.br\n    affiliations: Professor - IFPA\n  - name: \"Gabriel Henrique Gomes de Souza\"\n    affiliations: Bolsista PIBICTI/PROPPG/IFPA/CNPq\naffiliations: \"Instituto Federal do Pará - IFPA\"\nlang: \"pt\"\n---\n\n\n# Por que regressão?\n\n-   Inovação tecnológica envolve propor novas soluções ou aprimoramentos resolver problemas.\n-   Um resultado de um processo ou propriedade de algo pode ser entedido como uma variável que pode ser explicada por outra ou por outras variáveis.\n-   Posso descrever ou estimar o resultado dessa relação?\n-   Como posso melhorar as propriedades de materiais ou de um sistema conhecendo a sua relação com os principais fatores envolvidos?\n-   Como realizar os cálculos e gráficos dessas análise sem despesas?\n\n# Definição\n\nA **regressão** é uma técnica utilizada para explicar e modelar a relação entre uma variável *y* , denominada resposta ou variável dependente, e uma ou mais variáveis independentes, também denominadas fatores ou variáveis explicativas, *x1*,…,*xk* (Faraway 2002).\n\n$$y = f(x_1, x_2, \\dots, x_k)$$\n\nA variável dependente deve ser contínua, mas a(s) variável(is) independentes de podem ser contínuas, discretas ou categóricas.\n\nA regressão pode ser utilizadas para três finalidades básicas:\n\na)  **Descrição**: descrever a estrutura geral de dados;\nb)  **Análise**:Analisar os efeitos de variações nas variáveis independentes ou fatores sobre a variável dependente ou resposta; e\nc)  **Previsão**: estimar valores da variável dependente com base nos valores das variáveis independentes.\n\nA regressão busca explicar porque os valores de cada uma das observações de $y$ são diferentes umas das outras com base na informação dos valores de $x$ associados. O valor esperado de cada $y$ para cada valor de $x$, ou valor condicional de y, pode ser descrito inicialmente pelo seguinte modelo:\n\n$$E(y|x)=\\beta_0+\\beta_1X + \\epsilon$$\n\n\\noindent em que o intercepto $\\beta_0$ e ao coeficiente de inclinação $\\beta_i$ são constantes desconhecidas e $\\epsilon$ é uma compontente aleatória.\n\nA @fig-reta (a) apresenta um conjunto de observações de uma variável dependente (*y*) em resposta a diferentes valores de uma variável independente (*X*). Na @fig-reta (b), regressão busca traçar uma reta que cruze as observações dos pares ordenados $(x,y)$ com o melhor ajuste, isto é, com a menor distância entre os pontos e $\\beta_0$ e $\\beta_1$ são, respectivamente os coeficientes lineares e de inclinação dessa reta.\n\n\n::: {#fig-reta .cell .caption-top .fig-cap-location-top layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Dados](RegressaoConnepi_files/figure-html/fig-reta-1.png){#fig-reta-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Reta e parâmetros](RegressaoConnepi_files/figure-html/fig-reta-2.png){#fig-reta-2 width=672}\n:::\n\n A reta de regressão\n:::\n\n\nQuando há somente uma variável explicativa, *k=1*, chama-se **modelo de regressao simples**.\n\n$$y=\\beta_0+\\beta_1 X+ \\epsilon$$\n\n**y** é o valor da observado da variável dependente, $\\beta_0$ é intercepto ou coeficente linear, e $\\beta_i$ coeficiente de inclinação, $\\varepsilon_i$ é u termo aleatório normalmente distribuído com média zero e variância constante.\n\nQuando há mais de uma varável explicativa, *k\\>*1, chama-se **modelo de regressão múltipla**.\n\n$$E(y|x) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k+ \\epsilon$$\n\n$X_k$ são as variáveis independentes, $\\beta_0$ é uma constante que representa o coeficiente linear ou intercepto do modelo, $\\beta_1,\\dots,\\beta_k$ são os parâmetros de declividade ou coeficientes angulares associados às variáveis independentes.\n\nOs valores dos parâmetros $\\beta$ são desconhecidos, mas podem ser estimados a partir de dados amostrais, observados ou experimentais, de forma que os modelo estimado é o seguinte:\n\n$$y_i = b_0 + b_1 X_1 + b_2 X_2 + \\dots + b_k X_k+e_i\\:,\\:\\: i=1,\\dots,N$$\n\n$y_i$ é o valor da observado da variável dependente, *i* é o número da observação, *N* é o total de observações da amostra, $X_k$ são as variáveis independentes, $b_0$ é a estimativa do intercepto do modelo, $b_1,\\dots,b_k$ são as estimativas dos coeficientes angulares, $e_i$ é o valor do termo aleatório ou resíduo.\n\n# Estimativa do modelo\n\nUma vez de posse da estimativa de $\\beta$, o modelo permite estimar os valores da variável dependente contidos no vetor $\\hat{y}$:\n\n$$ \\hat{y}_i=b_0 + b_1 X_i$$\n\nO método dos MQO envolve encontrar $\\mathbf{b}$ que minimize a soma dos quadrados dos resíduos. O resíduo ($e_i$) pode ser definido como a diferença entre o valor observado ($y_i$) é aquele calculado pelo modelo, denominado valor ajustado ou previsto ($\\hat{y}$), podendo se expresso como abaixo\n\n$$e_i =y_i-\\hat{y}_i$$\n\nOs residuos são ilustrados na @fig-residuos e são estimativas dos valores do termo aleatório $\\epsilon$ os quais não são observáveis.\n\n\n\n::: {.cell .caption-top .fig-cap-location-top}\n::: {.cell-output-display}\n![Os resíduos](RegressaoConnepi_files/figure-html/fig-residuos-1.png){#fig-residuos width=672}\n:::\n:::\n\n\n\n# O que é o R?\n\nO R é um ambiente computacional aberto, destinado á análise de dados, disponível gratuitamente na internet e que possui uma ampla comunidade de colaboração volutária. Aliado ao ambiente de desenvolvimento integrado(IDE) RStudio, também disponível gratuitamente, oferece uma interface amigável e integração com outros programas,como o Quarto, o que possibilita a geração de relatórios instantâneos em HyperText Markup Language (HTML), Portable Document Format (PDF) e Microsoft Word. \n\nO programas podem ser baixados para instalaçao nos seguintes endereços.\n\n - [R](https://cran.r-project.org/bin/windows/base/){.external target=\"_blank\"}\n - [RStudio](https://posit.co/download/rstudio-desktop/){.external target=\"_blank\"}\n \nImportante, destacar que o R é o software que realizada os cálculos e gráficos e o RStudio é uma interface, portanto esta não irá funcionar sem o R estar instalado.\n\nAo ser instalado o R traz um conjunto de pacotes básicos. Um pacote é um conjunto de funções que permitem realizar as operações necessárias. Todavia, um conjunto de pacotes adicionais para inúmeros propósitos que podem ser instalados.\n\nA instalação de um pacote pode ser realizada por meio da função `install.packages()` com o nome do pacote desejado. Por exemplo, vamos instalar o pacote **readxl** que é útil para importar e exportar dados para Excel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"readxl\")\n```\n:::\n\n\nApós instalado, para que os seus recursos sejam ativados, é necessário carregá-lo com a função `library()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\n```\n:::\n\n\nOs recursos desse pacote adiocinal agora estão disponíveis\n\n\n\n# Lendo e examinando dados no R\n\nO dados estão na primeira aba do arquivo do excel  **dados.xlsx**. Para importar os dados, usa-se a função `read_excel()` do pacote **readxl** que deve ser instalado no R porque não é um pacote básico.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"readxl\")\n```\n:::\n\n\nAssim, pode-se carregar o pacote e  utilizar a função `read_excel()`. Os dados são salvos no objeto `dados`.\n\nOs valores do objeto `dados` podem ser exibidos no console pelo seu nome. As colunas podem ser acessadas, com o uso dos cifrões. A estrutura dos dados pode ser exibida com a função `str()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\ndados <- read_excel(\"dados.xlsx\", sheet = \"ex1_compressao\")\n\ndados\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n      pr   rca\n   <dbl> <dbl>\n 1     0  9.44\n 2     0  9.77\n 3     0 11.6 \n 4     0 10.1 \n 5     0 10.1 \n 6    10  8.72\n 7    10  7.46\n 8    10  5.73\n 9    10  6.31\n10    10  6.55\n11    20  5.22\n12    20  4.36\n13    20  4.4 \n14    20  4.11\n15    20  3.44\n```\n\n\n:::\n\n```{.r .cell-code}\ndados$pr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  0  0  0  0  0 10 10 10 10 10 20 20 20 20 20\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(dados)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [15 × 2] (S3: tbl_df/tbl/data.frame)\n $ pr : num [1:15] 0 0 0 0 0 10 10 10 10 10 ...\n $ rca: num [1:15] 9.44 9.77 11.56 10.07 10.13 ...\n```\n\n\n:::\n:::\n\n\nUm gráfico pode ser produzido com o comando `plot()`. Os argumentos podem ser informados de duas maneiras. A primeira inserido os valores das colunas individualmente, eixo horizontal e vertical. A segunda na forma de fórmula e indicando o objeto com os dados, nesse caso não precisa usar os cifrões.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(dados$pr,dados$rca,\n     xlab = \"Proporção de resíduos (%)\",\n     ylab = \"Resistência (MPa)\")\n```\n\n::: {.cell-output-display}\n![](RegressaoConnepi_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(rca~pr, data = dados,\n     xlab = \"Proporção de resíduos (%)\",\n     ylab = \"Resistência (MPa)\")\n```\n\n::: {.cell-output-display}\n![](RegressaoConnepi_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n# Ajustando modelo no R\n\nO ajuste ou estimação do modelo de regressão linear no R é relizado pela função `lm()`. Os argumentos devem ser inseridos na forma de fórmula. Os argumento `(rca ~ pr, data = dados)`, informam que se deve estimar o modelo de rca \"em função\" de pr e que os valores estão armazanados no objeto `dados`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(rca ~ pr, data = dados)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = rca ~ pr, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.42133 -0.62833 -0.02533  0.25067  1.56867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 10.09533    0.35828   28.18 4.85e-13 ***\npr          -0.29440    0.02775  -10.61 9.03e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8776 on 13 degrees of freedom\nMultiple R-squared:  0.8964,\tAdjusted R-squared:  0.8885 \nF-statistic: 112.5 on 1 and 13 DF,  p-value: 9.031e-08\n```\n\n\n:::\n:::\n\n\n# Qualidade do ajuste\n\nA qualidade do ajuste modelo é a avaliação da capacidade do modelo de regressão explicar as variações de valores da variável dependente, de fazer predições e quais variáveis ajudam nessa explicação. A seguir são descritas brevemente as medidas que permitem essas avaliações.\n\nA estatística **F Anova** (*F-statistic*) mede o efeito conjunto das variáveis independentes (fatores) sobre a variável dependente (resposta). Testa a hipótese nula de que nenhuma das variáveis independentes é capaz de descrever o comportamento da variável dependente. Para que o modelo de regressão proposto seja significativo, a hipótese nula deve ser rejeitada, em geral, quando $Valor-P < α = 0, 05$.\n\nO **Coeficiente de determinação** (*Multiple R-squared* - $R^2$) mede a proporção da variação explicada pela regressão e seu valor varia de 0 a 1, quanto maior esse valor, maior poder explicativo do modelo.\n\nNo caso de regressão múltipla, o **Coeficiente de determinação ajustado** (*Adjusted R-squared*) mede a proporção da variação explicada pela regressão, mas penaliza o número de variáveis independentes, uma vez que modelos parcimoniosos são preferíveis por sua simplicidade, logo, o acréscimo de uma variável e da complexidade devem ser justificados por um aumento razoável no poder explicativo.\n\nO **Erro Padrão do Erro** , ou *Residual Standard Error*, também denominado Raiz do Erro Quadrático médio, ou *Root Mean Squared Error (RMSE)*, mede o grau de dispersão em torno da linha de regressão e quanto menor o seu valor, melhor. No R, é calculado pela seguite Equação:\n\n$$\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n (y_i-\\hat{y}_i)^2}{n-k}}\n$$\n\nonde onde RMSE é expressa na mesma unidade de y, *n* é o número de observações e *k*, o número de parâmetros a serem estimados, o demoninador indica o número de graus de liberdade. Importante ressaltar que, no cáclulo do RSME, geralmente se dividem os desvios ao quadro por *n*, mas a divisão por $(n-k)$ permite a obtenção de um valor não viesado erro padrão do erro.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = rca ~ pr, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.42133 -0.62833 -0.02533  0.25067  1.56867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 10.09533    0.35828   28.18 4.85e-13 ***\npr          -0.29440    0.02775  -10.61 9.03e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8776 on 13 degrees of freedom\nMultiple R-squared:  0.8964,\tAdjusted R-squared:  0.8885 \nF-statistic: 112.5 on 1 and 13 DF,  p-value: 9.031e-08\n```\n\n\n:::\n:::\n\n\n# Pressupostos do Modelo de Regressão\n\n1.  **Linearidade** A relação entre as variáveis explicativas e a variável dependente é linear. A linearidade pode ser avaliada através da inspeção dos gráficos de dispersão ou de resíduos.\n\n2.  **Homocedasticidade**: A variância dos resíduos é constante para todos os valores de *X*. A dispersão dos resíduos deve se manter ao longo dos valores das variáveis independentes, como exibido na @fig-homohetero (a). Quando a dispersão, por exemplo, aumenta com os valores de X, como na @fig-homohetero (b) e ou se altera com algum padrão, como na @fig-homohetero (c), diz-se que o modelo apresenta heterocedasticidade.\n\n$$var(\\varepsilon|X_1, X_2, \\dots, X_k) = \\sigma^2$$\n\n\n::: {.cell .caption-top .fig-cap-location-top}\n::: {.cell-output-display}\n![Homocedasticidade e heterocedasticidade](img/heterocedasticidade.png){#fig-homohetero}\n:::\n:::\n\n\n3.  **Independência dos erros**: os valores de um erro (i) não influencia o valor de outro (j), expressa pelo valor nulo de qualquer par de covariância de erros aleatórios.\n\n$$cov(\\varepsilon_i,\\varepsilon_j)=0 \\; (i \\neq j)$$\n\nIsso implica que os valores de y também são estatisticamente independentes e visse-versa.\n\n$$cov(\\varepsilon_i,\\varepsilon_j)=cov(y_i,y_j)=0 \\; (i \\neq j)$$\n\n4.  Os erros seguem distribuição normal com média zero e variância constante.\n\n$$\\varepsilon_i \\sim N(0, \\sigma^2)$$\n\n$$E(\\varepsilon|X)=0$$\n\nque implica em afirmar que\n\n$$E(y|X)=\\beta_0+\\beta_1X_1+\\dots+\\beta_kX_k$$\n\n5.  **Não multicolinearidade perfeita**: as variáveis explicativas são linearmente independentes, isto é, não há correlação perfeita entre elas. A correlação elevada entre as variáveis independentes dificulta a determinação do efeito exato de cada uma sobre a variável dependente.\n\n| Pressuposto                   | Exame                                                                                                               |\n|------------------------------------|------------------------------------|\n| Linearidade                   | Gráfico de dispersão dos resíduos em função dos valores ajustados                                                   |\n| Homocedasticidade             | Gráfico de dispersão dos resíduos em função dos valores ajustados, gráfico (Scale-Location), Teste de Breusch-Pagan |\n| Normalidade zero dos resíduos | Gráfico de dispersão dos resíduos em função dos valores ajustados                                                   |\n| Normalidade                   | QQ-plot e teste de Shapiro-Wilk                                                                                     |\n| Independência dos resíduos    | Gráfico dos resíduos e Coeficiente de Autocorrelação                                                                |\n| Multicolinearidade            | Fator de inflação de variância (VIF) e Tolerância                                                                   |\n\n: Pressuspostos e técnicas de exame\n\n# Avaliação dos pressupostos\n\nA avaliação dos pressupostos da regressão, na maior parte, é realizada por meio de exames dos resíduos na forma de gráficos e de testes estatísticos. No R, alguns exames podem ser aplicados diretamente ao objeto em que o modelo foi salvo, mas outros exigem que os valores dos resíduos sejam extraídos.\n\nOs valores do modelo salvo em `mod` podem ser acessado com o uso do cifrão. Digite o nome do objeto acrescente o cifrão que uma lista de valores será apresentada. Nos comandos a seguir são extraídos os valores dos resíduos e os valores ajustados do modelo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod$residuals\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          1           2           3           4           5           6 \n-0.65533333 -0.32533333  1.46466667 -0.02533333  0.03466667  1.56866667 \n          7           8           9          10          11          12 \n 0.30866667 -1.42133333 -0.84133333 -0.60133333  1.01266667  0.15266667 \n         13          14          15 \n 0.19266667 -0.09733333 -0.76733333 \n```\n\n\n:::\n\n```{.r .cell-code}\nmod$fitted.values\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        1         2         3         4         5         6         7         8 \n10.095333 10.095333 10.095333 10.095333 10.095333  7.151333  7.151333  7.151333 \n        9        10        11        12        13        14        15 \n 7.151333  7.151333  4.207333  4.207333  4.207333  4.207333  4.207333 \n```\n\n\n:::\n:::\n\n\nA @fig-resfit é um gráfico de dispersão de resíduos em função dos valores ajustados e permite o exame visual da **linearidade** do modelo da **homocedasticidade**. A linha horizontal foi traçada na altura da média dos resíduos.\n\n\n::: {.cell .fig-cap-location-top}\n\n```{.r .cell-code}\nplot(mod$fitted.values, mod$residuals)\nabline(h = mean(mod$residuals), lty = 2, col = \"red\")\n```\n\n::: {.cell-output-display}\n![Resíduos em função dos valores ajustados](RegressaoConnepi_files/figure-html/fig-resfit-1.png){#fig-resfit width=672}\n:::\n:::\n\n\nA **normalidade** pode ser examinda por meio do gráfico quantil-quantil (*Normal qqplot*) e de um teste de aderência, aqui utilizaremos o teste de Shapiro-Wilk.\n\nO *Normal Q-Q plot* é utilizado para exame visual da normalidade das observações, podendo ser elaborado com as funções `qqnorm()` e `qqline()`, tendo como principal argumento os resíduos do modelo. Caso os dados sejam normalmente distribuídos os pontos devem se situar aleatoriamente próximos à reta.\n\nO Normal Q-Q plot, na fig-qqplot, mostra que a maior parte dos resíduos está próximo da, no entanto, três valores se afastam mais, exigindo um exame formal para verificar se esse afastamento é grave.\n\n\n::: {.cell .fig-cap-location-top}\n\n```{.r .cell-code}\nqqnorm(mod$residuals, col = \"red\")\nqqline(mod$residuals)\n```\n\n::: {.cell-output-display}\n![Resíduos em função dos valores ajustados](RegressaoConnepi_files/figure-html/fig-qqplot-1.png){#fig-qqplot width=672}\n:::\n:::\n\n\nO teste de Shapiro-Wilk é um teste formal de distribuição de normalidade que testa as seguites hipóteses:\n\n-   $H_0$: Os dado seguem distribuição normal.\n-   $H_1$: Os dado NÃO seguem distribuição normal.\n\nConsiderando um nível de significância de 0,05, rejeita-se a hipótese nula se $p<0,05$, caso contrário aceita-se a afirmação de normalidade. Então o que se espera é que $p>0,05$, indicando normalidade e continuidade da análise sem a violação desse pressuposto.\n\nA função `shapiro.test()` exibe os valores da estatística de teste (*W*), que é uma qui-quadrado, e o *valor P*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mod$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mod$residuals\nW = 0.94907, p-value = 0.51\n```\n\n\n:::\n:::\n\n\nA análise da **homecedasticidade** pode ser realizado por inspeção visual do gráfico de dispersão dos resíduos em função dos valores ajustados, na @fig-resfit, pelo gráfico Scale-Location (a ser apresentado adiante) e com o teste de Breusch-Pagan.\n\nO teste de Breusch-Pagan avalia as seguites hipóteses:\n\n-   $H_0$: Homocedasticidade presente.\n-   $H_1$: Heterocedasticidade presente.\n\nConsiderando um nível de significância de 0,05, rejeita-se a hipótese nula se $p<0,05$, indicando a presença de heterocedasticidade, caso contrário aceita-se a afirmação de homocedasticidade.\n\nA função `bptest()` do pacote **lmtest** efetua o teste de Breusch-Pagan, mas antes o pacote precisa ser instalado por meio da função `install.packages()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"lmtest\")\n```\n:::\n\n\nNo resultado do função, BP corresponde à estística de teste e o seu correspondente valor P = 0.7031, por ser superior 0,05, é não é significante, de forma que não se pode rejeitar a hipótese nula e indica homocedasticidade.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\nbptest(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  mod\nBP = 0.14522, df = 1, p-value = 0.7031\n```\n\n\n:::\n:::\n\n\nUm resurso muito ágil e amplo de avaliar os presssupostos do modelo são os *gráficos de diagnóstico do modelo* acionados pela conjugação da função `plot()` e o objeto com as dados do modelo.\n\nTrata-se de 4 gráficos que são acionados e apresentados a medida que pressiona ENTER no console.\n\na)  Resíduos vs valores ajustados;\nb)  QQplot dos resíduos;\nc)  Scale-location;\nd)  Resíduos vs alavangem (*Residuals vs Leverage*)\n\nTodavia, é mais confortável, dividir-se a janela gráfica e quatro partes e se apresentar todos juntos para um exame mais rápido. A divisão da janela em 2 linhas e 2 colunas é relizada com o comando `par(mfrow = c(2,2))`. Em seguida, digita-se o comando para geração dos 4 gráficos de diagnósticos do modelo, conforme apresentados na @fig-diagnosticos.\n\n\n::: {.cell .fig-cap-location-top}\n\n```{.r .cell-code}\npar(mfrow = c(2,2))\nplot(mod)\n```\n\n::: {.cell-output-display}\n![Gráficos de diagnóstico do modelo](RegressaoConnepi_files/figure-html/fig-diagnosticos-1.png){#fig-diagnosticos width=672}\n:::\n:::\n\n\nO primeiro é o gráfico de **resíduos vs valores ajustados**, já elaborado anteriomente na @fig-resfit, sendi útil para o exame da linearidade e da homocedasticidade, mas com o acréscimo de uma linha central para facilitar a análise da dispersão das observações. No caso de linearidade, a linha vermelha será rasoavelmente horizontal, mas caso reste algum padrão não linear nos resíduos, a linha vermelha refletirá tal padrão.\n\nO gráfico não revela padrões restantes nos resíduos e a linha vermelha, apesar do leve vale em X=7, é rasoavelmente horizontal, de forma que não há indícios de violação da linearidade. O três números destacados (3, 6 e 8) indicam três maiores resíduos, mas não são necessariamente atípicos (*outliers*).\n\nO segundo gráfico é o **QQplot** permite o exame de normalidade e já foi elaborado na @fig-qqplot, chamando atenção para três valores que se afastam da reta.\n\nO terceiro gráfico é o **scale-location** que é a dispersão dos raízes dos resíduos padronizados em função dos valores ajustados sendo útil para o exame da homocedasticidade. Em caso de homocedasticidade, a linha vermelha será razoavelmente horizontal e os pontos devem se dispersar de forma similar ao longo dos valores ajustados.\n\nO gráfico revela alguma suspeita de dispersão ligeiramente maior no valor 10, mas a linha vermelha não exibe tendência, portanto, é apesar não não haver indícios de dispersão heterôgenea grave dos resíduos, é prudente incluir um teste formal na análise, o qual já foi realizado pelo teste de Breusch-Pagan anteriormente.\n\nO quarto é o gráfico de **Resíduos vs alavangem** (*Residuals vs Leverage*) destinado à identificação de valores atípicos (*outliers*). Os valores limites para que determinadas observações devam ser avaliadas como possível outlier são as distâncias de Cook que mensuram a influência que as observaçoes exercem sobre a estimativa do modelo. Os valores de corte são apresentadas como linhas tracejadas no interior do gráfico e a intepretação dos seus valores podem são apresentadas na Tabela abaixo.\n\n| D           | Interpretação                                 |\n|-------------|-----------------------------------------------|\n| $D<0,5$     | Não são é uma observação atípica|\n| $0,5< D \\leq 1$| Geralmente útil estudar a influência de tais observações|\n| $D>1$| Deve-se avaliar a sua exclusão da  amostra.\n\n: Interpretação da distância de Cook\n\nO Residuals vs Leverage na @fig-diagnosticos não exibe observações ultrapassando alguma linha de corte da distância de Cook, aliás apenas parte uma linha de D=0,5 aparace no canto superior direito do gráfico, de modo que não há indícios de valores atípicos na amostra.\n\nUm gráfico com os valores individuais da distância de Cook podem ser exibidos num único gráfico. Para retornar para uma janela sem divisão basta digitar `par(mfrow = c(1,1))` e o próximo gráfico será gerado em janela única. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1,1))\n```\n:::\n\n\nNo comando de gráficos de diagnósticos, identifique que deve ser exibido somente o quarto gráfico.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mod, which = 4)\n```\n\n::: {.cell-output-display}\n![](RegressaoConnepi_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "RegressaoConnepi_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}